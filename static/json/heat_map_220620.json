[
  {
    "id": "0",
    "aspect": "log",
    "volume": "10",
    "sentiment": "0.7",
    "size": "3.002585092994046",
    "body": "\"Hi  @ChenAllen0305 ,I recommend that you open the log and look at broker.log, where you can see the details of the ��error��, and we can also address specific errors\"",
    "": ""
  },
  {
    "id": "1",
    "aspect": "config",
    "volume": "9",
    "sentiment": "0.6666666666666666",
    "size": "2.863891244002886",
    "body": "\"@lizhiboo Yes",
    "": ""
  },
  {
    "id": "2",
    "aspect": "consumer",
    "volume": "8",
    "sentiment": "0.5",
    "size": "2.5794415416798357",
    "body": "\"> Got it, please pay some attention to [��SimpleConsumer��](https://github.com/apache/rocketmq-clients/tree/master/java) and the implementation of server-side: https://github.com/apache/rocketmq/pull/4225 \"",
    "": ""
  },
  {
    "id": "3",
    "aspect": "broker",
    "volume": "7",
    "sentiment": "0.5714285714285714",
    "size": "2.5173387204838846",
    "body": "1 change the level to info2 execute the command `.\\mqadmin.cmd updateAclConfig -n 10.0.0.23:9876 -b 10.0.0.23:10911 -a test-cl -s 12345678 -i PUB|SUB`3 provide the ��broker.log�� file",
    "": ""
  },
  {
    "id": "4",
    "aspect": "pop",
    "volume": "6",
    "sentiment": "0.6666666666666666",
    "size": "2.4584261358947215",
    "body": "@fujian-zfj Good catch! Only PUT_ OK is write success when we put CK or ACK into the store in ��pop�� mode.",
    "": ""
  },
  {
    "id": "5",
    "aspect": "client",
    "volume": "5",
    "sentiment": "1.0",
    "size": "2.6094379124341005",
    "body": "It will cause the ��client�� to fail when the master goes down.is this reasonable��I always thought the client was insensitive",
    "": ""
  },
  {
    "id": "6",
    "aspect": "problem",
    "volume": "5",
    "sentiment": "0.4",
    "size": "2.0094379124341004",
    "body": "\"> Current SusscriptionType will be auto set when user call [DefaultLitePullConsumer.assign() ](https://github.com/apache/rocketmq/blob/316d32a006ea49ed806aa965890c917020c426c2/client/src/main/java/org/apache/rocketmq/client/consumer/DefaultLitePullConsumer.java#L269)> > does this solve your ��problem����Our business scenario requires a preview of the five most recent or earliest messages for a certain tag under a certain topic. So I try to use` org.apache.rocketmq.client.consumer.DefaultLitePullConsumer#seekToBegin` and `org.apache.rocketmq.client.consumer. DefaultLitePullConsumer#seek` api , but `seek` doesn't seem to work with `org.apache.rocketmq.client.consumer.LitePullConsumer#subscribe`, resulting in the inability to customize subExpression. I tried to rewrite `org.apache.rocketmq.client.impl.consumer.DefaultLitePullConsumerImpl#assign` to support custom subExpressions under ASSIGN SubscriptionType��![image](https://user-images.githubusercontent.com/39700308/176070098-ae519a08-c16e-4d34-b86e-178a60240775.png)This seems to work.But I'm not sure if this causes other problems and why it's not natively supported.\"",
    "": ""
  },
  {
    "id": "7",
    "aspect": "topic",
    "volume": "4",
    "sentiment": "0.25",
    "size": "1.6362943611198906",
    "body": "Good catch! I think there are two ��solutions����1. deleteTopic subCommand only operate master broker2. Remove the verification of slave in delete topic process in brokerI prefer the formerCould you submit a pull request to fix the issue?",
    "": ""
  },
  {
    "id": "8",
    "aspect": "method",
    "volume": "4",
    "sentiment": "1.25",
    "size": "2.636294361119891",
    "body": "\"Hi @novicate ,there have three ��advises�� and hope these can help you1. abstract class can not be definition to static2. extend should be extends3. The Consumer should `Override` onMessage method Have a great day!\"",
    "": ""
  },
  {
    "id": "9",
    "aspect": "message",
    "volume": "4",
    "sentiment": "0.75",
    "size": "2.136294361119891",
    "body": "\"@shengminw can u describe any scenario for adjusting ��maxMessageSize�� in production? maxMessageSize in broker is corresponding to maxMessageSize in DefaultMQProducer. IMO, maxMessageSize is known to uses before usage, and users should avoid to sender message larger than maxMessageSize.\"",
    "": ""
  },
  {
    "id": "10",
    "aspect": "disk",
    "volume": "3",
    "sentiment": "0.6666666666666666",
    "size": "1.7652789553347765",
    "body": "Same problem here.Still not work after I tried `��fileReservedTime�� ` and `��diskMaxUsedSpaceRatio�� `  both",
    "": ""
  },
  {
    "id": "11",
    "aspect": "synchronized",
    "volume": "3",
    "sentiment": "0.6666666666666666",
    "size": "1.7652789553347765",
    "body": "\"I looked again and found 1��`FileAppender` other method like `org.apache.rocketmq.logging.inner.LoggingBuilder.FileAppender#setFile(java.lang.String)` is not decorated by ��synchronized�� , Is it necessary here and other places��2��for `fileName` field is direct use like `this.fileName` , not use `getFile()` , so is there a ��concurrency�� issue here?Forgive me for more questions....etc , thx again\"",
    "": ""
  },
  {
    "id": "12",
    "aspect": "bug",
    "volume": "3",
    "sentiment": "1.0",
    "size": "2.09861228866811",
    "body": "\"so this ��bug�� does exists��you can new a pr @liuzongliang0202 ,@tsunghanjacktsai do you think that\"",
    "": ""
  },
  {
    "id": "13",
    "aspect": "producer",
    "volume": "3",
    "sentiment": "0.6666666666666666",
    "size": "1.7652789553347765",
    "body": "\"@shengminw can u describe any scenario for adjusting ��maxMessageSize�� in production? maxMessageSize in broker is corresponding to maxMessageSize in DefaultMQProducer. IMO, maxMessageSize is known to uses before usage, and users should avoid to sender message larger than maxMessageSize.\"",
    "": ""
  },
  {
    "id": "14",
    "aspect": "offset",
    "volume": "3",
    "sentiment": "0.6666666666666666",
    "size": "1.7652789553347765",
    "body": "\"The initial ��offset�� is 0, what's the problem? org.apache.rocketmq.common.UtilAll#offset2FileName\"",
    "": ""
  },
  {
    "id": "15",
    "aspect": "timeout",
    "volume": "3",
    "sentiment": "0.3333333333333333",
    "size": "1.431945622001443",
    "body": "\"![image](https://user-images.githubusercontent.com/29321745/182794480-8081e3c2-17fa-4fc7-8931-5ee857bd5423.png)This is because the first send exceeds the set ��timeout��, so it will not continue to retry. I think this restriction should be removed and the timeout should be recalculated when retrying\"",
    "": ""
  },
  {
    "id": "16",
    "aspect": "variable",
    "volume": "3",
    "sentiment": "0.6666666666666666",
    "size": "1.7652789553347765",
    "body": "Current ��SusscriptionType�� will be auto set when user call [DefaultLitePullConsumer.assign() ](https://github.com/apache/rocketmq/blob/316d32a006ea49ed806aa965890c917020c426c2/client/src/main/java/org/apache/rocketmq/client/consumer/DefaultLitePullConsumer.java#L269)does this solve your problem��",
    "": ""
  },
  {
    "id": "17",
    "aspect": "concurrency",
    "volume": "3",
    "sentiment": "0.6666666666666666",
    "size": "1.7652789553347765",
    "body": "\"@Oliverwqcwrw It seems that TransactionalMessageServiceImpl.check() is only called by TransactionalMessageCheckService, and TransactionalMessageCheckService is a scheduled task. Maybe no need to concern ��concurrency�� problem.\"",
    "": ""
  },
  {
    "id": "18",
    "aspect": "docker",
    "volume": "3",
    "sentiment": "0.6666666666666666",
    "size": "1.7652789553347765",
    "body": "\"The following command works. Maybe you could refer to documents of ��docker�� for more information.`docker run -it --net=host --mount type=bind,source=/tmp/,target=/home/rocketmq/store apache/rocketmq ./mqbroker`\"",
    "": ""
  },
  {
    "id": "19",
    "aspect": "error",
    "volume": "2",
    "sentiment": "1.0",
    "size": "1.6931471805599454",
    "body": "\"Hi  @ChenAllen0305 ,I recommend that you open the log and look at broker.log, where you can see the details of the ��error��, and we can also address specific errors\"",
    "": ""
  },
  {
    "id": "20",
    "aspect": "question",
    "volume": "2",
    "sentiment": "0.5",
    "size": "1.1931471805599454",
    "body": "\"> Sorry, I set it false to test other ��question��.Here is the detail :2022-07-01 16:12:46 INFO AclFileWatchService - The default acl dir E:\\rocketmq\\rocketmq-all-4.9.4-bin-release\\conf\\acl is not exist2022-07-01 16:12:46 INFO HeartbeatThread_2 - new consumer connected, group: groupTest CONSUME_PASSIVELY BROADCASTING channel: ClientChannelInfo [channel=[id: 0x3b84cb2d, L:/10.0.0.23:10911 - R:/10.0.0.23:64975], clientId=10.0.0.23@DEFAULT, language=JAVA, version=399, lastUpdateTimestamp=1656663166908]2022-07-01 16:12:46 INFO HeartbeatThread_2 - subscription changed, add new topic, group: groupTest SubscriptionData [classFilterMode=false, topic=%RETRY%group1, subString=*, tagsSet=[], codeSet=[], subVersion=1656662986541, expressionType=TAG]2022-07-01 16:12:46 INFO HeartbeatThread_2 - registerConsumer info changed ConsumerData [groupName=groupTest, consumeType=CONSUME_PASSIVELY, messageModel=BROADCASTING, consumeFromWhere=CONSUME_FROM_LAST_OFFSET, unitMode=false, subscriptionDataSet=[SubscriptionData [classFilterMode=false, topic=%RETRY%group1, subString=*, tagsSet=[], codeSet=[], subVersion=1656662986541, expressionType=TAG]]] 10.0.0.23:649752022-07-01 16:12:46 INFO HeartbeatThread_2 - new producer connected, group: CLIENT_INNER_PRODUCER channel: ClientChannelInfo [channel=[id: 0x3b84cb2d, L:/10.0.0.23:10911 - R:/10.0.0.23:64975], clientId=10.0.0.23@DEFAULT, language=JAVA, version=399, lastUpdateTimestamp=1656663166920]2022-07-01 16:12:46 INFO brokerOutApi_thread_2 - register broker[0]to name server localhost:9876 OK2022-07-01 16:12:51 INFO AclFileWatchService - The default acl dir E:\\rocketmq\\rocketmq-all-4.9.4-bin-release\\conf\\acl is not exist2022-07-01 16:12:56 INFO AclFileWatchService - The default acl dir E:\\rocketmq\\rocketmq-all-4.9.4-bin-release\\conf\\acl is not exist2022-07-01 16:13:01 INFO AclFileWatchService - The default acl dir E:\\rocketmq\\rocketmq-all-4.9.4-bin-release\\conf\\acl is not exist2022-07-01 16:13:01 INFO HeartbeatThread_3 - new producer connected, group: CLIENT_INNER_PRODUCER channel: ClientChannelInfo [channel=[id: 0x6085362e, L:/10.0.0.23:10911 - R:/10.0.0.23:65373], clientId=10.0.0.23@1656662310197, language=JAVA, version=399, lastUpdateTimestamp=1656663181526]2022-07-01 16:13:02 INFO HeartbeatThread_4 - new producer connected, group: CLIENT_INNER_PRODUCER channel: ClientChannelInfo [channel=[id: 0x7ff76071, L:/10.0.0.23:10911 - R:/10.0.0.23:65411], clientId=10.0.0.23@1656662310854, language=JAVA, version=399, lastUpdateTimestamp=1656663182525]2022-07-01 16:13:02 INFO HeartbeatThread_2 - new producer connected, group: CLIENT_INNER_PRODUCER channel: ClientChannelInfo [channel=[id: 0x1aef2a36, L:/10.0.0.23:10911 - R:/10.0.0.23:65413], clientId=10.0.0.23@1656662310874, language=JAVA, version=399, lastUpdateTimestamp=1656663182537]2022-07-01 16:13:02 INFO HeartbeatThread_1 - new producer connected, group: CLIENT_INNER_PRODUCER channel: ClientChannelInfo [channel=[id: 0xbc866c30, L:/10.0.0.23:10911 - R:/10.0.0.23:65412], clientId=10.0.0.23@1656662310876, language=JAVA, version=399, lastUpdateTimestamp=1656663182537]2022-07-01 16:13:02 INFO HeartbeatThread_3 - new producer connected, group: CLIENT_INNER_PRODUCER channel: ClientChannelInfo [channel=[id: 0xa044c5f9, L:/10.0.0.23:10911 - R:/10.0.0.23:65414], clientId=10.0.0.23@1656662310868, language=JAVA, version=399, lastUpdateTimestamp=1656663182550]2022-07-01 16:13:02 INFO HeartbeatThread_4 - new producer connected, group: CLIENT_INNER_PRODUCER channel: ClientChannelInfo [channel=[id: 0xce15d8ff, L:/10.0.0.23:10911 - R:/10.0.0.23:65415], clientId=10.0.0.23@1656662310852, language=JAVA, version=399, lastUpdateTimestamp=1656663182550]2022-07-01 16:13:02 INFO HeartbeatThread_2 - new producer connected, group: CLIENT_INNER_PRODUCER channel: ClientChannelInfo [channel=[id: 0x6c777bf1, L:/10.0.0.23:10911 - R:/10.0.0.23:65416], clientId=10.0.0.23@1656662310899, language=JAVA, version=399, lastUpdateTimestamp=1656663182566]2022-07-01 16:13:02 INFO HeartbeatThread_1 - new producer connected, group: CLIENT_INNER_PRODUCER channel: ClientChannelInfo [channel=[id: 0xed2365a6, L:/10.0.0.23:10911 - R:/10.0.0.23:65417], clientId=10.0.0.23@1656662310905, language=JAVA, version=399, lastUpdateTimestamp=1656663182566]2022-07-01 16:13:06 INFO AclFileWatchService - The default acl dir E:\\rocketmq\\rocketmq-all-4.9.4-bin-release\\conf\\acl is not exist2022-07-01 16:13:11 INFO AclFileWatchService - The default acl dir E:\\rocketmq\\rocketmq-all-4.9.4-bin-release\\conf\\acl is not exist\"",
    "": ""
  },
  {
    "id": "21",
    "aspect": "issue",
    "volume": "2",
    "sentiment": "0.5",
    "size": "1.1931471805599454",
    "body": "\"@xmzhao71 i will close ��issue��, if have any other question, u can creat a new issue, thanks.\"",
    "": ""
  },
  {
    "id": "22",
    "aspect": "acl",
    "volume": "2",
    "sentiment": "1.0",
    "size": "1.6931471805599454",
    "body": "\"The info of `The default acl dir E:\\rocketmq\\rocketmq-all-4.9.4-bin-release\\conf\\acl is not exist` can not affect ��udateAclConfig��, I can not see the error log, you execute the command `.\\mqadmin.cmd updateAclConfig -n 10.0.0.23:9876 -b 10.0.0.23:10911 -a test-cl -s 12345678 -i PUB|SUB` and observe if there have error,.by the way,  broker.conf need config namesrvAddr\"",
    "": ""
  },
  {
    "id": "23",
    "aspect": "reference",
    "volume": "2",
    "sentiment": "0.5",
    "size": "1.1931471805599454",
    "body": "\"> Hi! I would love to help out for this. This is my first time working on an open source project. Is there a reference I can consult for building these test cases?Great, u can ��refer�� PlainPermissionManagerTest, it already contains some test case, and u can just add these test case in PlainPermissionManagerTest.\"",
    "": ""
  },
  {
    "id": "24",
    "aspect": "argument",
    "volume": "2",
    "sentiment": "0.5",
    "size": "1.1931471805599454",
    "body": "\"the `source` ��argument�� should be a `volume` name default, unless you specified the `type` argument\"",
    "": ""
  },
  {
    "id": "25",
    "aspect": "version",
    "volume": "2",
    "sentiment": "0.0",
    "size": "0.6931471805599453",
    "body": "\"I remember this conf/acl dir exists version 4.9.3, but it cannot work with ��updateAclConfig��\"",
    "": ""
  },
  {
    "id": "26",
    "aspect": "lts",
    "volume": "2",
    "sentiment": "2.0",
    "size": "2.6931471805599454",
    "body": "\"@zergduan I am the original designer and author of this ��feature��.1. Yes...It is designed to behave this way.2. Have you configured the following Java options? -Dtls.server.need.client.auth=required -Dtls.server.trustCertPath=path-to-your-ca-certsSee https://github.com/apache/rocketmq/blob/a62b70bc25423c1d7e18043e32af427d29ef9ac4/remoting/src/main/java/org/apache/rocketmq/remoting/netty/TlsHelper.java#L140 to inspect how server SslContext is constructed.RocketMQ is pretty flexible in terms of ��TLS��.... It could be configured to work in multiple mode, PlainText, mTLS, or TLS with one side certificate verification: either client-verify-server's certificate or server-verify-client's certificate. \"",
    "": ""
  },
  {
    "id": "27",
    "aspect": "messagequeue",
    "volume": "2",
    "sentiment": "0.0",
    "size": "0.6931471805599453",
    "body": "Hi @sunxiaojian You can add a public method to get the ��AssignedMessageQueue��.",
    "": ""
  },
  {
    "id": "28",
    "aspect": "verify",
    "volume": "2",
    "sentiment": "0.5",
    "size": "1.1931471805599454",
    "body": "Good catch! I think there are two ��solutions����1. deleteTopic subCommand only operate master broker2. Remove the verification of slave in delete topic process in brokerI prefer the formerCould you submit a pull request to fix the issue?",
    "": ""
  },
  {
    "id": "29",
    "aspect": "master",
    "volume": "2",
    "sentiment": "0.5",
    "size": "1.1931471805599454",
    "body": "\"> No one modified it. It is strange that the same error occurred on four ��master�� servers at the same time.Later after deleting stored, the pressure test again did not reproduce this problem.\"",
    "": ""
  },
  {
    "id": "30",
    "aspect": "rip",
    "volume": "2",
    "sentiment": "0.5",
    "size": "1.1931471805599454",
    "body": "\"@shengminw In your ��RIP��:> So the deletion should be executed when any of the disks reached the threshold (set by diskMaxUsedSpaceRatio)Is this a good idea? Attempting to delete expiring data is pretty expensive, which may compete IOPS with normal data persistence, causing unexpected latency spikes.Another issue: similar to https://github.com/apache/rocketmq/issues/4803 Watermarks measured in percent are inferior to those measured in kilobytes(megabytes) as Linux kernel does. The reclamation of RocketMQ should follow the same way.\"",
    "": ""
  },
  {
    "id": "31",
    "aspect": "leadership",
    "volume": "2",
    "sentiment": "0.0",
    "size": "0.6931471805599453",
    "body": "\"> Hi @TheR1sing3un, It seems that the function of #4798 is duplicated.It seems like they are different, one is a command to elect master in brokers, another is a commadn to transfer ��leadership�� in controllers(controllers is a raft cluster)\"",
    "": ""
  },
  {
    "id": "32",
    "aspect": "ip",
    "volume": "2",
    "sentiment": "1.0",
    "size": "1.6931471805599454",
    "body": "\"Hi @mxsm, this is a known issue. The current controller uses ��IP�� as the unique identity of the broker, which causes this problem. Now, @hzh0425 has started to solve this issue. We can review this PR together. #4672\"",
    "": ""
  },
  {
    "id": "33",
    "aspect": "authenticatio",
    "volume": "1",
    "sentiment": "1.0",
    "size": "1.0",
    "body": "\"@zergduan a. RocketMQ support mutual ��authentication�� and one-way authentication.b. yes",
    "": ""
  },
  {
    "id": "34",
    "aspect": "metadata",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"as I know",
    "": ""
  },
  {
    "id": "35",
    "aspect": "logic",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"If diskspacewarninglevelratio is less than diskspaceclenforciblyratio, it will never go to the ��logic�� that`if(minPhysicRatio > diskspaceclenforciblyratio)`\"",
    "": ""
  },
  {
    "id": "36",
    "aspect": "diagnosis",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"To facilitate ��diagnosis��, it makes sense to prefix all thread-pool naming patterns with instance-name of the client\"",
    "": ""
  },
  {
    "id": "37",
    "aspect": "design",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"If there are problems in the current ��design��, could you please provide a demo to prove the specific ��problem��, so that we can analyze the problem and solve it together, WDYT?\"",
    "": ""
  },
  {
    "id": "38",
    "aspect": "file",
    "volume": "1",
    "sentiment": "1.0",
    "size": "1.0",
    "body": "Same problem here.Still not work after I tried `��fileReservedTime�� ` and `��diskMaxUsedSpaceRatio�� `  both",
    "": ""
  },
  {
    "id": "39",
    "aspect": "rpc",
    "volume": "1",
    "sentiment": "1.0",
    "size": "1.0",
    "body": "\"Now that `bname` is supported in RpcRequestHeader, related ��RPC�� can use this field to implement.\"",
    "": ""
  },
  {
    "id": "40",
    "aspect": "override",
    "volume": "1",
    "sentiment": "3.0",
    "size": "3.0",
    "body": "\"Hi @novicate ,there have three ��advises�� and hope these can help you1. abstract class can not be definition to static2. extend should be extends3. The Consumer should `Override` onMessage method Have a great day!\"",
    "": ""
  },
  {
    "id": "41",
    "aspect": "feature",
    "volume": "1",
    "sentiment": "2.0",
    "size": "2.0",
    "body": "\"@zergduan I am the original designer and author of this ��feature��.1. Yes...It is designed to behave this way.2. Have you configured the following Java options? -Dtls.server.need.client.auth=required -Dtls.server.trustCertPath=path-to-your-ca-certsSee https://github.com/apache/rocketmq/blob/a62b70bc25423c1d7e18043e32af427d29ef9ac4/remoting/src/main/java/org/apache/rocketmq/remoting/netty/TlsHelper.java#L140 to inspect how server SslContext is constructed.RocketMQ is pretty flexible in terms of ��TLS��.... It could be configured to work in multiple mode, PlainText, mTLS, or TLS with one side certificate verification: either client-verify-server's certificate or server-verify-client's certificate. \"",
    "": ""
  },
  {
    "id": "42",
    "aspect": "watermark",
    "volume": "1",
    "sentiment": "1.0",
    "size": "1.0",
    "body": "\"@guyinyou By design, this is to define the reclamation policy of the default message store and kick off the reclaiming thread when free disk space is running low. The whole design is pretty similar to how [Linux manages memory](https://blogs.oracle.com/linux/post/anticipating-your-memory-needs)With that said, we may have two improvements:1. ��Watermarks�� measured in megabytes are better than the ratio. Imagine, disks with a capacity of 100G expect a much more urgent action than those with a capacity of 4T if both of them have 15% disks free;2.  Free disk watermarks of min, low, and high (in Linux kernel terms) shall be validated before getting applied, where min <= low <= high.\"",
    "": ""
  },
  {
    "id": "43",
    "aspect": "download",
    "volume": "1",
    "sentiment": "1.0",
    "size": "1.0",
    "body": "\"I had the same issue today. I realized it would take too much effort to fix it; fortunately, you can ��download�� RocketMQ binary from their site. It's more convenient to do so if you're not planning to do any changes in source code.\"",
    "": ""
  },
  {
    "id": "44",
    "aspect": "offline",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"> > > > > > > > > > > > > > > Hi @TheR1sing3un, It seems that the function of #4798 is duplicated.> > > > > > > > > > > > It seems like they are different, one is a command to elect master in brokers, another is a commadn to transfer leadership in controllers(controllers is a raft cluster)> > > > > > > > > I want to add this command to transfer leadership from controller-master to its controller-follower(based on the leadertransfer feature in dledger)> > > > > > Could you explain the usage scenario again? It would be better to have an example.> > In this case, this command may be helpful. ![WechatIMG16](https://user-images.githubusercontent.com/87409330/185161030-c9f04154-4471-4e8a-b2c8-c958441bc0cd.jpeg) backgroud:> > * in asymmetric network partition,> * controller-leader can connect to other controller-followers> * all brokers can connect to two controller-follower, but can't connect to controller-leader> * because the network in controllers is normal, so the controller-leader is always leader> * because none of brokers can send hearbeat to controller-master, so the controller-leader can't elect any new master in brokers> * so now the cluster lose the HAIn this case, it seems that it would be better to go ��offline�� the controller-leader directly.\"",
    "": ""
  },
  {
    "id": "45",
    "aspect": "prefix",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "@zxy1994 Yes... I am wondering if the ��prefix�� ConsumerGroup is general enough to meet all potential use cases. Some users may have multiple consumer objects of the same group within the same process. Then they would not able to differentiate them again.",
    "": ""
  },
  {
    "id": "46",
    "aspect": "process",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"@zergduan the whole ��process�� is right, u can try it in practice to verify it.\"",
    "": ""
  },
  {
    "id": "47",
    "aspect": "stream",
    "volume": "1",
    "sentiment": "1.0",
    "size": "1.0",
    "body": "There are problems after closing the ��stream�� while printing ��logs�� asynchronously",
    "": ""
  },
  {
    "id": "48",
    "aspect": "status",
    "volume": "1",
    "sentiment": "1.0",
    "size": "1.0",
    "body": "\"@vergilyn IMO, depending on consumeExecutor's ��status�� is also not correct, consumeExecutor is still running, its status is always changing. if set awaitTerminationMillsWhenShutdown 0, ConsumeExecutor.awaitTermination method blocks until all tasks have completed execution after a shutdown request, or the current thread is interrupted. If user do not call thread.interrupt, it will keep waiting until all tasks have completed.\"",
    "": ""
  },
  {
    "id": "49",
    "aspect": "response",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"> Hi , @ChenAllen0305 I notice your OS is windows, you can use `mqadmin.cmd` to replace `mqadmin` to try itI change 'mqadmin.cmd' and try it in windows, it give same ��response��.Also I try to use updateAclConfig in local service, below is response:sh mqadmin updateAclConfig -n 10.0.0.23:9876 -b 10.0.0.23:10911 -a test-cl -s 12345678 -i PUB|SUB-bash: SUB: command not found\"",
    "": ""
  },
  {
    "id": "50",
    "aspect": "consistent",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"Thanks for your reply IMO, I think it would be more appropriate for getFile to wait while setFile() is executed. Indeed, there is no place to call `getFile()` at present, but if someone calls it in the future, ��inconsistent�� behavior may occur\"",
    "": ""
  },
  {
    "id": "51",
    "aspect": "node",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"![image](https://user-images.githubusercontent.com/24563036/178910736-eb203817-dc87-43dd-84b6-62a249722cd7.png)this is console, third ��node�� is missing\"",
    "": ""
  },
  {
    "id": "52",
    "aspect": "repo",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"We create a new ��repo�� named \"\"rocketmq-schema-registry\"\". Welcome review and comments. The pull request is: [RIP 42](https://github.com/apache/rocketmq-schema-registry/pull/1)\"",
    "": ""
  },
  {
    "id": "53",
    "aspect": "jars",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"> you can look at [rocketmq-docker](https://github.com/apache/rocketmq-docker/tree/master/image-build), and edit the Dockerfile and replace the file `rocketmq-all-${ROCKETMQ_VERSION}-bin-release.zip`��Jars�� packaged with Maven do not have a bin directory\"",
    "": ""
  },
  {
    "id": "54",
    "aspect": "whiteremoteaddress",
    "volume": "1",
    "sentiment": "1.0",
    "size": "1.0",
    "body": "\"i am sorry",
    "": ""
  },
  {
    "id": "55",
    "aspect": "api",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"Hi @mxsm If you want to get the brokerMemberGroup, I suggest putting the contents in the body like the registerBroker or getReplicainfo ��API��.\"",
    "": ""
  },
  {
    "id": "56",
    "aspect": "wal",
    "volume": "1",
    "sentiment": "1.0",
    "size": "1.0",
    "body": "\"I believe this is a design flaw. Leader/master nodes shall **ONLY** replicate their ��WAL�� logs to their peers/slaves. All activities, including updates of consume-offsets, should be reflected in the WAL log. Peer nodes and slaves restore state machines by replaying WAL.The current implementation has more than one replication path, this is the root cause of the discrepancy.\"",
    "": ""
  },
  {
    "id": "57",
    "aspect": "resource",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"��Resources�� should be loaded using ClassLoader, instead of concatenating paths manually.\"",
    "": ""
  },
  {
    "id": "58",
    "aspect": "nameserver",
    "volume": "1",
    "sentiment": "1.0",
    "size": "1.0",
    "body": "\"@zhangleiouc ��Nettyserverconfig�� is used not only for namesrv, but also for brokers\"",
    "": ""
  },
  {
    "id": "59",
    "aspect": "memory",
    "volume": "1",
    "sentiment": "3.0",
    "size": "3.0",
    "body": "\"@running-ball IMO, machine ��memory�� is insufficient, so linux core killed it. Have a try to set rocketmq-3's broker memory to 4g.\"",
    "": ""
  },
  {
    "id": "60",
    "aspect": "constructor",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"IMO, This ��constructor�� seems does not appear to be called concurrently\"",
    "": ""
  },
  {
    "id": "61",
    "aspect": "slave",
    "volume": "1",
    "sentiment": "1.0",
    "size": "1.0",
    "body": "> It seems that the error is caused by the ��message�� being sent to the slave node. Sorry for ignoring the description that there is no standby node. Let's first check the configuration of the broker side according to @lizhanhui's guideline",
    "": ""
  },
  {
    "id": "62",
    "aspect": "mistake",
    "volume": "1",
    "sentiment": "1.0",
    "size": "1.0",
    "body": "I know the reason for my ��mistake��",
    "": ""
  },
  {
    "id": "63",
    "aspect": "implementation",
    "volume": "1",
    "sentiment": "1.0",
    "size": "1.0",
    "body": "\"@lizhiboo sorry",
    "": "executor));                }            }        } catch (InterruptedException ie) {            // (Re-)Cancel if current thread also interrupted.            executor.shutdownNow();            // Preserve interrupt status.            Thread.currentThread().interrupt();        }    }```\""
  },
  {
    "id": "64",
    "aspect": "doc",
    "volume": "1",
    "sentiment": "2.0",
    "size": "2.0",
    "body": "\"in ��doc�� , some words are wrong.. that are confusing me![image](https://user-images.githubusercontent.com/12888788/179143065-3cf043ff-b431-41b1-be72-0c7985a04ed9.png)the letter `e` -> `d`\"",
    "": ""
  },
  {
    "id": "65",
    "aspect": "class",
    "volume": "1",
    "sentiment": "3.0",
    "size": "3.0",
    "body": "\"Hi @novicate ,there have three ��advises�� and hope these can help you1. abstract class can not be definition to static2. extend should be extends3. The Consumer should `Override` onMessage method Have a great day!\"",
    "": ""
  },
  {
    "id": "66",
    "aspect": "filter",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "We'd better add a ��filter�� or ��interceptor chain�� before pub/sub each message.",
    "": ""
  },
  {
    "id": "67",
    "aspect": "windows",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"Hi , @ChenAllen0305 I notice your ��OS�� is windows, you can use `mqadmin.cmd` to replace `mqadmin` to try it\"",
    "": ""
  },
  {
    "id": "68",
    "aspect": "pr",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"@xiaoheng1 got catch, can u submit a ��pr�� to fulfill this?\"",
    "": ""
  },
  {
    "id": "69",
    "aspect": "imo",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "\"Finally, this issue is raised again.��IMO��, the retry strategy on the client side needs significant refinement. I suggest creating a RIP to improve this. We need something similar to what gRPC-client-retry strategy https://github.com/grpc/proposal/blob/master/A6-client-retries.md\"",
    "": ""
  },
  {
    "id": "70",
    "aspect": "code",
    "volume": "1",
    "sentiment": "0.0",
    "size": "0.0",
    "body": "It seems that this ��code�� snippet was optimized in 5.0 beta.",
    "": ""
  },
  {
    "id": "71",
    "aspect": "test",
    "volume": "1",
    "sentiment": "1.0",
    "size": "1.0",
    "body": "\"thanks , I will ��test�� it on my env.\"",
    "": ""
  }
]
